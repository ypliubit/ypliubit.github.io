
<!DOCTYPE html>
<html lang="en">
<body>
    <main>
        <h2>ELIP: Enhanced Visual-Language Foundation Models for Image Retrieval</h2>
        <p>Guanqi Zhan<sup>1*</sup>, Yuanpei Liu<sup>2*</sup>, Kai Han<sup>2</sup>, Weidi Xie<sup>1,3</sup> and Andrew Zisserman<sup>1</sup></p>
        <p>Affiliations: <br>
           <sup>1</sup>VGG, University of Oxford <br>
           <sup>2</sup>The University of Hong Kong <br>
            <sup>3</sup>Shanghai Jiao Tong University
        </p>
        <p><strong>Abstract:</strong>
            The objective in this paper is to improve the performance of text-to-image retrieval. To this end, we introduce a new framework that can boost the performance of large-scale pre-trained vision-language models, so that they can be used for text-to-image re-ranking. The approach, \textbf{Enhanced Language-Image Pre-training} (\textbf{ELIP}), uses the text query to predict \update{a group of visual prompts} to condition the ViT image encoding. ELIP can easily be applied to the commonly used CLIP and the state-of-the-art BLIP-2 architectures. To train the architecture  with limited computing resources, we develop a `student friendly' \emph{best practice} involving global hard sample mining, and selection and curation of a large-scale dataset. On the evaluation side, we set up two new out-of-distribution benchmarks, \emph{Occluded COCO} and \emph{ImageNet-R}, to assess the zero-shot generalisation of the models to different domains. Benefiting from the novel architecture and data curation, experiments show our enhanced network significantly boosts CLIP performance and outperforms the state-of-the-art BLIP-2 model on text-to-image retrieval.
        </p>
        
        <h3>Publication Details</h3>
        <p>arxiv,2025.</p>

        <h3>BibTeX Citation</h3>
        <pre>
        @inproceedings{2025elip,
            title={ELIP: Enhanced Visual-Language Foundation Models for Image Retrieval},
            author={Guanqi Zhan, Yuanpei Liu, Kai Han, Weidi Xie and Andrew Zisserman},
            booktitle={arxiv},
            year={2025}
        }
        </pre>

        <h3>Links</h3>
        <p><a href="https://link-to-your-paper.com">Paper Link</a></p>
        <p><a href="https://github.com/username/paper-repo">GitHub Repository</a></p>
    </main>
    <footer>
        <p>&copy; 2025</p>
    </footer>
</body>
</html>
